{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ITEM-BASED COLLABORATIVE FILTERING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.ml.recommendation import ALS\n",
    "from pyspark.sql import Row\n",
    "from pyspark.sql.functions import lit\n",
    "\n",
    "# Load up movie ID -> movie name dictionary\n",
    "def loadMovieNames():\n",
    "    movieNames = {}\n",
    "    with open(\"/home/vijay/Desktop/Studies/Data world/github/Recommended System/ml-100k/ml-100k/u.item\",encoding=\"ISO-8859-1\") as f:\n",
    "        for line in f:\n",
    "            fields = line.split('|')        \n",
    "            movieNames[int(fields[0])] = (fields[1])\n",
    "    return movieNames\n",
    "\n",
    "# Convert u.data lines into (userID, movieID, rating) rows\n",
    "def parseInput(line):\n",
    "    fields = line.value.split()\n",
    "    return Row(userID = int(fields[0]), movieID = int(fields[1]), rating = float(fields[2]))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Ratings for user ID 0:\n",
      "Empire Strikes Back, The (1980) 5.0\n",
      "Gone with the Wind (1939) 1.0\n",
      "Star Wars (1977) 5.0\n",
      "\n",
      "Top 20 recommendations:\n",
      "Army of Darkness (1993) 6.030475616455078\n",
      "Mystery Science Theater 3000: The Movie (1996) 5.912016868591309\n",
      "Ace Ventura: Pet Detective (1994) 5.344579696655273\n",
      "Princess Bride, The (1987) 5.124341011047363\n",
      "Star Wars (1977) 5.003631591796875\n",
      "Empire Strikes Back, The (1980) 4.993403434753418\n",
      "Blues Brothers, The (1980) 4.920345306396484\n",
      "Return of the Jedi (1983) 4.721105098724365\n",
      "Jackie Chan's First Strike (1996) 4.7001261711120605\n",
      "Terminator, The (1984) 4.6889543533325195\n",
      "Highlander (1986) 4.640594959259033\n",
      "Raiders of the Lost Ark (1981) 4.6026201248168945\n",
      "Beavis and Butt-head Do America (1996) 4.545560359954834\n",
      "Nightmare on Elm Street, A (1984) 4.451655864715576\n",
      "Star Trek: The Wrath of Khan (1982) 4.4491119384765625\n",
      "Con Air (1997) 4.395421028137207\n",
      "Hudsucker Proxy, The (1994) 4.2855305671691895\n",
      "Austin Powers: International Man of Mystery (1997) 4.259584426879883\n",
      "Terminator 2: Judgment Day (1991) 4.196341514587402\n",
      "Monty Python and the Holy Grail (1974) 4.139435291290283\n"
     ]
    }
   ],
   "source": [
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Create a SparkSession (the config bit is only for Windows!)\n",
    "    spark = SparkSession.builder.appName(\"MovieRecs\").getOrCreate()\n",
    "\n",
    "    # Load up our movie ID -> name dictionary\n",
    "    movieNames = loadMovieNames()\n",
    "\n",
    "    # Get the raw data\n",
    "    lines = spark.read.text(\"/home/vijay/Desktop/Studies/Data world/github/Recommended System/ml-100k/ml-100k/u.data\").rdd\n",
    "\n",
    "    # Convert it to a RDD of Row objects with (userID, movieID, rating)\n",
    "    ratingsRDD = lines.map(parseInput)\n",
    "\n",
    "    # Convert to a DataFrame and cache it\n",
    "    ratings = spark.createDataFrame(ratingsRDD).cache()\n",
    "\n",
    "    # Create an ALS collaborative filtering model from the complete data set\n",
    "    als = ALS(maxIter=10, regParam=0.001, userCol=\"userID\", itemCol=\"movieID\", ratingCol=\"rating\")\n",
    "    model = als.fit(ratings)\n",
    "\n",
    "    # Print out ratings from user 0:\n",
    "    print(\"\\nRatings for user ID 0:\")\n",
    "    userRatings = ratings.filter(\"userID = 0\")\n",
    "    for rating in userRatings.collect():\n",
    "        print(movieNames[rating['movieID']], rating['rating'])\n",
    "        \n",
    "\n",
    "    print(\"\\nTop 20 recommendations:\")\n",
    "    # Find movies rated more than 100 times\n",
    "    ratingCounts = ratings.groupBy(\"movieID\").count().filter(\"count > 100\")\n",
    "    # Construct a \"test\" dataframe for user 0 with every movie rated more than 100 times\n",
    "    popularMovies = ratingCounts.select(\"movieID\").withColumn('userID', lit(0))\n",
    "    \n",
    "    \n",
    "    # Run our model on that list of popular movies for user ID 0\n",
    "    recommendations = model.transform(popularMovies)\n",
    "\n",
    "    # Get the top 20 movies with the highest predicted rating for this user\n",
    "    topRecommendations = recommendations.sort(recommendations.prediction.desc()).take(20)\n",
    "\n",
    "    for recommendation in topRecommendations:\n",
    "        print (movieNames[recommendation['movieID']], recommendation['prediction'])\n",
    "\n",
    "    spark.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
